{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import primesieve as ps\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "\n",
    "from dataloader import read_dataset\n",
    "from file_ops import get_LMFDB_all_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test curves dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LMFDB curves - just to be able to remove them from custom dataset\n",
    "\n",
    "data_all_LMFDB, _ = read_dataset(\n",
    "    get_LMFDB_all_file_names(), 10, load_reduced_metadata=True)\n",
    "conductors_LMFDB = set([elem['conductor'] for elem in data_all_LMFDB])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom dataset curves and ap-s and remove all curves having conductors from LMFDB or conductor > 10^8\n",
    "\n",
    "num_exp=1000  # primes p < num_exp\n",
    "data_all, data_qexp = read_dataset([\"od_Matije/curves_r01triv\", \"od_Matije/curves_svi\"], num_exp)\n",
    "conductors = [elem['conductor'] for elem in data_all]\n",
    "idxs = [idx for idx, cond in enumerate(conductors) if ((cond <= 100000000) and (cond not in conductors_LMFDB))]\n",
    "\n",
    "data_qexp = data_qexp[idxs]\n",
    "idxs = set(idxs)\n",
    "data_all = [elem for idx, elem in enumerate(\n",
    "    tqdm(data_all, leave=False)) if idx in idxs]\n",
    "\n",
    "conductors = [elem['conductor'] for elem in data_all]\n",
    "assert len(conductors) == data_qexp.shape[0]\n",
    "len(conductors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save conductors and ap-s from selected curves\n",
    "\n",
    "N=10000  # number of curves to test on\n",
    "\n",
    "with open('conductors.txt', 'w') as out_file:\n",
    "    file_content = \"\\n\".join([str(cond) for cond in conductors[-N:]])\n",
    "    out_file.write(file_content)\n",
    "\n",
    "np.savetxt('aps.txt', data_qexp[-N:], fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that curves and ap-s can be loaded - can skip this\n",
    "\n",
    "loaded_conductors = pd.read_csv('conductors.txt', names=['conductor'])\n",
    "assert list(loaded_conductors['conductor']) == conductors[-N:]\n",
    "\n",
    "loaded_data_qexp = pd.read_csv(\n",
    "    'aps.txt', names=[f'p{prime}' for prime in list(ps.primes(num_exp))]).to_numpy()\n",
    "assert np.array_equal(loaded_data_qexp, data_qexp[-N:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run deepellrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run deepellrank from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After running deepellrank - plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precomputed true ranks from custom dataset\n",
    "\n",
    "true_ranks = [elem['rank'] for elem in data_all][-N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predicted ranks\n",
    "\n",
    "predicted_ranks = pd.read_csv('predicted_ranks.txt', names=['rank'])\n",
    "predicted_ranks = list(predicted_ranks['rank'])\n",
    "assert len(true_ranks) == len(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MCC\n",
    "matthews_corrcoef(true_ranks, predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(true_ranks, predicted_ranks)\n",
    "print(cf_matrix.shape)\n",
    "df_cm = pd.DataFrame(\n",
    "    cf_matrix / np.sum(cf_matrix) * 100,\n",
    "    index=[i for i in sorted(list(set(true_ranks).union(set(predicted_ranks))))],\n",
    "    columns=[i for i in sorted(list(set(true_ranks).union(set(predicted_ranks))))]\n",
    ")\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c87a8dc8267c396218601ad79fb029f342111bdb17db254b664ec285beb16c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
